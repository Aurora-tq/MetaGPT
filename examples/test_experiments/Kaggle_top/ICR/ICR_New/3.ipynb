{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\nfrom tensorflow.keras import regularizers as R\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras import optimizers as O\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.losses import binary_crossentropy\ntf.keras.utils.set_random_seed(722)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-31T14:23:15.346942Z","iopub.execute_input":"2023-05-31T14:23:15.347631Z","iopub.status.idle":"2023-05-31T14:23:27.134078Z","shell.execute_reply.started":"2023-05-31T14:23:15.347594Z","shell.execute_reply":"2023-05-31T14:23:27.133168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv', index_col='Id')\ntest_df = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv', index_col='Id')\n\ntrain_df['EJ'] = train_df['EJ'].replace({'A': 0, 'B': 1})\ntest_df['EJ'] = test_df['EJ'].replace({'A': 0, 'B': 1})\n\nnan_fill = train_df.isna().any()\nnan_fill *= train_df.min() - train_df.max()\nnan_fill[nan_fill == 0] = train_df.median()\ntrain_df = train_df.fillna(nan_fill)\ntest_df = test_df.fillna(nan_fill)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:23:33.767955Z","iopub.execute_input":"2023-05-31T14:23:33.768352Z","iopub.status.idle":"2023-05-31T14:23:33.879127Z","shell.execute_reply.started":"2023-05-31T14:23:33.768323Z","shell.execute_reply":"2023-05-31T14:23:33.877988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test_df.values","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:23:34.118907Z","iopub.execute_input":"2023-05-31T14:23:34.119326Z","iopub.status.idle":"2023-05-31T14:23:34.124924Z","shell.execute_reply.started":"2023-05-31T14:23:34.119295Z","shell.execute_reply":"2023-05-31T14:23:34.12413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.keras.utils.register_keras_serializable()\ndef smish(x):\n    return x * K.tanh(K.log(1 + K.sigmoid(x)))\n\n\n@tf.keras.utils.register_keras_serializable()\nclass GatedLinearUnit(L.Layer):\n    def __init__(self, units, **kwargs):\n        super().__init__(**kwargs)\n        self.linear = L.Dense(units)\n        self.sigmoid = L.Dense(units, activation=\"sigmoid\")\n        self.units = units\n\n    def get_config(self):\n        config = super().get_config()\n        config['units'] = self.units\n        return config\n    \n    def call(self, inputs):\n        return self.linear(inputs) * self.sigmoid(inputs)\n    \n\n@tf.keras.utils.register_keras_serializable()\nclass GatedResidualNetwork(L.Layer):\n    def __init__(self, units, dropout_rate, **kwargs):\n        super().__init__(**kwargs)\n        self.units = units\n        self.dropout_rate = dropout_rate\n        self.relu_dense = L.Dense(units, activation=smish)\n        self.linear_dense = L.Dense(units)\n        self.dropout = L.Dropout(dropout_rate)\n        self.gated_linear_unit = GatedLinearUnit(units)\n        self.layer_norm = L.LayerNormalization()\n        self.project = L.Dense(units)\n\n    def get_config(self):\n        config = super().get_config()\n        config['units'] = self.units\n        config['dropout_rate'] = self.dropout_rate\n        return config\n    \n    def call(self, inputs):\n        x = self.relu_dense(inputs)\n        x = self.linear_dense(x)\n        x = self.dropout(x)\n        if inputs.shape[-1] != self.units:\n            inputs = self.project(inputs)\n        x = inputs + self.gated_linear_unit(x)\n        x = self.layer_norm(x)\n        return x\n    \n\n@tf.keras.utils.register_keras_serializable()\nclass VariableSelection(L.Layer):\n    def __init__(self, num_features, units, dropout_rate, **kwargs):\n        super().__init__(**kwargs)\n        self.grns = list()\n        # Create a GRN for each feature independently\n        for idx in range(num_features):\n            grn = GatedResidualNetwork(units, dropout_rate)\n            self.grns.append(grn)\n        # Create a GRN for the concatenation of all the features\n        self.grn_concat = GatedResidualNetwork(units, dropout_rate)\n        self.softmax = L.Dense(units=num_features, activation=\"softmax\")\n        self.num_features = num_features\n        self.units = units\n        self.dropout_rate = dropout_rate\n\n    def get_config(self):\n        config = super().get_config()\n        config['num_features'] = self.num_features\n        config['units'] = self.units\n        config['dropout_rate'] = self.dropout_rate\n        return config\n    \n    def call(self, inputs):\n        v = L.concatenate(inputs)\n        v = self.grn_concat(v)\n        v = tf.expand_dims(self.softmax(v), axis=-1)\n\n        x = []\n        for idx, input_ in enumerate(inputs):\n            x.append(self.grns[idx](input_))\n        x = tf.stack(x, axis=1)\n\n        outputs = tf.squeeze(tf.matmul(v, x, transpose_a=True), axis=1)\n        return outputs\n    \n\n@tf.keras.utils.register_keras_serializable()\nclass VariableSelectionFlow(L.Layer):\n    def __init__(self, num_features, units, dropout_rate, dense_units=None, **kwargs):\n        super().__init__(**kwargs)\n        self.variableselection = VariableSelection(num_features, units, dropout_rate)\n        self.split = L.Lambda(lambda t: tf.split(t, num_features, axis=-1))\n        self.dense = dense_units\n        if dense_units:\n            self.dense_list = [L.Dense(dense_units, \\\n                                       activation='linear') \\\n                               for _ in tf.range(num_features)\n                              ]\n        self.num_features = num_features\n        self.units = units\n        self.dropout_rate = dropout_rate\n        self.dense_units = dense_units\n        \n    def get_config(self):\n        config = super().get_config()\n        config['num_features'] = self.num_features\n        config['units'] = self.units\n        config['dropout_rate'] = self.dropout_rate\n        config['dense_units'] = self.dense_units\n        return config        \n    \n    def call(self, inputs):\n        split_input = self.split(inputs)\n        if self.dense:\n            l = [self.dense_list[i](split_input[i]) for i in range(len(self.dense_list))]\n        else:\n            l = split_input\n        return self.variableselection(l)        ","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:23:34.523687Z","iopub.execute_input":"2023-05-31T14:23:34.524271Z","iopub.status.idle":"2023-05-31T14:23:34.551393Z","shell.execute_reply.started":"2023-05-31T14:23:34.524233Z","shell.execute_reply":"2023-05-31T14:23:34.550578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mfolder = '/kaggle/input/icr-tf-adv-models/'\nmodels_weights = os.listdir(mfolder)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:27:59.92025Z","iopub.execute_input":"2023-05-31T14:27:59.920618Z","iopub.status.idle":"2023-05-31T14:27:59.927019Z","shell.execute_reply.started":"2023-05-31T14:27:59.920586Z","shell.execute_reply":"2023-05-31T14:27:59.925746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.zeros_like(test_df.iloc[:,0].values, dtype=np.float32)\nbatch_size = 32\n\nunits_1 = 32\ndrop_1 = 0.75\ndense_units = 8\n\nunits_2 = 16\ndrop_2 = 0.5\n\nunits_3 = 8\ndrop_3 = 0.25\n\nfor n, model_weights in enumerate(models_weights):\n    inputs_1 = tf.keras.Input(shape=(56,))\n        \n    features_1 = VariableSelectionFlow(56, units_1, drop_1, dense_units=dense_units)(inputs_1)\n    features_2 = VariableSelectionFlow(units_1, units_2, drop_2)(features_1)         \n    features_3 = VariableSelectionFlow(units_2, units_3, drop_3)(features_2)         \n\n    outputs = L.Dense(1, activation=\"sigmoid\")(features_3)\n\n    model = Model(inputs=inputs_1, outputs=outputs)      \n    model.load_weights(mfolder + model_weights)\n    y_pred += model.predict(X_test)[:,0]\n","metadata":{"execution":{"iopub.status.busy":"2023-05-31T14:58:17.408115Z","iopub.execute_input":"2023-05-31T14:58:17.408626Z","iopub.status.idle":"2023-05-31T15:06:50.331462Z","shell.execute_reply.started":"2023-05-31T14:58:17.408568Z","shell.execute_reply":"2023-05-31T15:06:50.329641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred /= len(models_weights)\np1 = y_pred\np0 = 1 - p1\np = np.stack([p0, p1]).T\nclass_0_est_instances = p[:,0].sum()\nothers_est_instances = p[:,1:].sum()\nnew_p = p * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(p.shape[1])]])\nnew_p = new_p / np.sum(new_p, axis=1, keepdims=1)\n\ntest_df[['class_0', 'class_1']] = new_p\ntest_df[['class_0', 'class_1']].to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-31T15:37:15.480805Z","iopub.execute_input":"2023-05-31T15:37:15.481418Z","iopub.status.idle":"2023-05-31T15:37:15.503423Z","shell.execute_reply.started":"2023-05-31T15:37:15.481266Z","shell.execute_reply":"2023-05-31T15:37:15.501703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}