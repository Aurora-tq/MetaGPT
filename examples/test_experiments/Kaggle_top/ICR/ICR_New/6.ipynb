{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr/pip-packages\n!mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n!cp /kaggle/input/pip-packages-icr/pip-packages/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:51:47.22804Z","iopub.execute_input":"2023-08-10T23:51:47.228498Z","iopub.status.idle":"2023-08-10T23:52:00.751384Z","shell.execute_reply.started":"2023-08-10T23:51:47.228458Z","shell.execute_reply":"2023-08-10T23:52:00.749806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder,normalize\nfrom sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.impute import SimpleImputer\nimport imblearn\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nimport xgboost\nimport inspect\nfrom collections import defaultdict\nfrom tabpfn import TabPFNClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:00.759966Z","iopub.execute_input":"2023-08-10T23:52:00.761986Z","iopub.status.idle":"2023-08-10T23:52:03.456052Z","shell.execute_reply.started":"2023-08-10T23:52:00.761948Z","shell.execute_reply":"2023-08-10T23:52:03.455058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ntest = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\nsample = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')\ngreeks = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/greeks.csv')\n\ntrain.drop([\"BC\",\"CL\"],axis = 1,inplace = True)\ntest.drop([\"BC\",\"CL\"],axis = 1,inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:03.457551Z","iopub.execute_input":"2023-08-10T23:52:03.458205Z","iopub.status.idle":"2023-08-10T23:52:03.494052Z","shell.execute_reply.started":"2023-08-10T23:52:03.458176Z","shell.execute_reply":"2023-08-10T23:52:03.493161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_category = train.EJ.unique()[1]\ntrain.EJ = train.EJ.eq(first_category).astype('int')\ntest.EJ = test.EJ.eq(first_category).astype('int')","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:03.496524Z","iopub.execute_input":"2023-08-10T23:52:03.49684Z","iopub.status.idle":"2023-08-10T23:52:03.505918Z","shell.execute_reply.started":"2023-08-10T23:52:03.496809Z","shell.execute_reply":"2023-08-10T23:52:03.50481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_under_sampler(df):\n    # Calculate the number of samples for each label. \n    neg, pos = np.bincount(df['Class'])\n\n    # Choose the samples with class label `1`.\n    one_df = df.loc[df['Class'] == 1] \n    # Choose the samples with class label `0`.\n    zero_df = df.loc[df['Class'] == 0]\n    # Select `pos` number of negative samples.\n    # This makes sure that we have equal number of samples for each label.\n    zero_df = zero_df.sample(n=pos)\n\n    # Join both label dataframes.\n    undersampled_df = pd.concat([zero_df, one_df])\n\n    # Shuffle the data and return\n    return undersampled_df.sample(frac = 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:03.507204Z","iopub.execute_input":"2023-08-10T23:52:03.507732Z","iopub.status.idle":"2023-08-10T23:52:03.518866Z","shell.execute_reply.started":"2023-08-10T23:52:03.507683Z","shell.execute_reply":"2023-08-10T23:52:03.517749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_good = random_under_sampler(train)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:03.520363Z","iopub.execute_input":"2023-08-10T23:52:03.521015Z","iopub.status.idle":"2023-08-10T23:52:03.535103Z","shell.execute_reply.started":"2023-08-10T23:52:03.520973Z","shell.execute_reply":"2023-08-10T23:52:03.534044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_good.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:03.536661Z","iopub.execute_input":"2023-08-10T23:52:03.53707Z","iopub.status.idle":"2023-08-10T23:52:03.547161Z","shell.execute_reply.started":"2023-08-10T23:52:03.537036Z","shell.execute_reply":"2023-08-10T23:52:03.546077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor_columns = [n for n in train.columns if n != 'Class' and n != 'Id']\nx= train[predictor_columns]\ny = train['Class']","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:03.548994Z","iopub.execute_input":"2023-08-10T23:52:03.549825Z","iopub.status.idle":"2023-08-10T23:52:03.557855Z","shell.execute_reply.started":"2023-08-10T23:52:03.549788Z","shell.execute_reply":"2023-08-10T23:52:03.557144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold as KF, GridSearchCV\ncv_outer = KF(n_splits = 20, shuffle=True, random_state=42)\ncv_inner = KF(n_splits = 10, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:03.559474Z","iopub.execute_input":"2023-08-10T23:52:03.560221Z","iopub.status.idle":"2023-08-10T23:52:03.571372Z","shell.execute_reply.started":"2023-08-10T23:52:03.560183Z","shell.execute_reply":"2023-08-10T23:52:03.570281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def balanced_log_loss(y_true, y_pred):\n    # y_true: correct labels 0, 1\n    # y_pred: predicted probabilities of class=1\n    # calculate the number of observations for each class\n    N_0 = np.sum(1 - y_true)\n    N_1 = np.sum(y_true)\n    # calculate the weights for each class to balance classes\n    w_0 = 1 / N_0\n    w_1 = 1 / N_1\n    # calculate the predicted probabilities for each class\n    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n    p_0 = 1 - p_1\n    # calculate the summed log loss for each class\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n    log_loss_1 = -np.sum(y_true * np.log(p_1))\n    # calculate the weighted summed logarithmic loss\n    # (factgor of 2 included to give same result as LL with balanced input)\n    balanced_log_loss = 2*(w_0 * log_loss_0 + w_1 * log_loss_1) / (w_0 + w_1)\n    # return the average log loss\n    return balanced_log_loss/(N_0+N_1)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:03.575695Z","iopub.execute_input":"2023-08-10T23:52:03.576047Z","iopub.status.idle":"2023-08-10T23:52:03.587246Z","shell.execute_reply.started":"2023-08-10T23:52:03.576018Z","shell.execute_reply":"2023-08-10T23:52:03.586507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import normalize\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nclass Ensemble():\n    def __init__(self):\n        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n\n        self.classifiers = [\n            XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.2, subsample=0.9, colsample_bytree=0.85),\n            XGBClassifier(alpha = 0.0013152238563360378, max_depth = 10, eta = 0.19506559985823185, gamma = 0.0007856091054954562, grow_policy = 'lossguide',\n                          subsample = 0.6793443403969917, colsample_bytree = 0.728216187335501, min_child_weight = 6,random_state= 42),\n            XGBClassifier(alpha = 0.0013152238563360378, max_depth = 10, eta = 0.19506559985823185, gamma = 0.0007856091054954562, grow_policy = 'lossguide',\n                          subsample = 0.6793443403969917, colsample_bytree = 0.728216187335501, min_child_weight = 6,random_state= 7),\n            LGBMClassifier(),\n            LogisticRegression(max_iter=200),\n            TabPFNClassifier(N_ensemble_configurations=24, device=\"cuda:0\"),\n            TabPFNClassifier(N_ensemble_configurations=64, device=\"cuda:0\"),\n            TabPFNClassifier(N_ensemble_configurations=264, device=\"cuda:0\"),\n            \n        ]\n    \n    def fit(self, X, y):\n        y = y.values\n        unique_classes, y = np.unique(y, return_inverse=True)\n        self.classes_ = unique_classes\n        first_category = X.EJ.unique()[1]\n        X.EJ = X.EJ.eq(first_category).astype('int')\n        X = self.imputer.fit_transform(X)\n        # X = normalize(X, axis=0)\n        j = 0 \n        for classifier in self.classifiers:\n            j += 1\n            if j > len(self.classifiers)-3 :\n                classifier.fit(X, y, overwrite_warning=True)\n            else:\n                classifier.fit(X, y)\n     \n    def predict_proba(self, x):\n        x = self.imputer.transform(x)\n        # x = normalize(x, axis=0)\n        probabilities = np.stack([classifier.predict_proba(x) for classifier in self.classifiers])\n        averaged_probabilities = np.mean(probabilities, axis=0)\n        class_0_est_instances = averaged_probabilities[:, 0].sum()\n        others_est_instances = averaged_probabilities[:, 1:].sum()\n        # Weighted probabilities based on class imbalance\n        new_probabilities = averaged_probabilities * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(averaged_probabilities.shape[1])]])\n        return new_probabilities / np.sum(new_probabilities, axis=1, keepdims=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:03.588913Z","iopub.execute_input":"2023-08-10T23:52:03.589532Z","iopub.status.idle":"2023-08-10T23:52:04.727144Z","shell.execute_reply.started":"2023-08-10T23:52:03.589495Z","shell.execute_reply":"2023-08-10T23:52:04.726076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:04.728375Z","iopub.execute_input":"2023-08-10T23:52:04.728719Z","iopub.status.idle":"2023-08-10T23:52:04.734616Z","shell.execute_reply.started":"2023-08-10T23:52:04.728686Z","shell.execute_reply":"2023-08-10T23:52:04.733589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training(model, x,y,y_meta):\n    outer_results = list()\n    best_loss = np.inf\n    split = 0\n    splits = 5\n    for train_idx,val_idx in tqdm(cv_inner.split(x), total = splits):\n        split+=1\n        x_train, x_val = x.iloc[train_idx],x.iloc[val_idx]\n        y_train, y_val = y_meta.iloc[train_idx], y.iloc[val_idx]\n                \n        model.fit(x_train, y_train)\n        y_pred = model.predict_proba(x_val)\n        probabilities = np.concatenate((y_pred[:,:1], np.sum(y_pred[:,1:], 1, keepdims=True)), axis=1)\n        p0 = probabilities[:,:1]\n#         p0[p0 > 0.86] = 1\n#         p0[p0 < 0.14] = 0\n        y_p = np.empty((y_pred.shape[0],))\n        for i in range(y_pred.shape[0]):\n            if p0[i]>=0.5:\n                y_p[i]= False\n            else :\n                y_p[i]=True\n        y_p = y_p.astype(int)\n        loss = balanced_log_loss(y_val,y_p)\n\n        if loss<best_loss:\n            best_model = model\n            best_loss = loss\n            print('best_model_saved')\n        outer_results.append(loss)\n        print('>val_loss=%.5f, split = %.1f' % (loss,split))\n    print('LOSS: %.5f' % (np.mean(outer_results)))\n    return best_model\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:04.736687Z","iopub.execute_input":"2023-08-10T23:52:04.737477Z","iopub.status.idle":"2023-08-10T23:52:04.749437Z","shell.execute_reply.started":"2023-08-10T23:52:04.73744Z","shell.execute_reply":"2023-08-10T23:52:04.748281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\ntimes = greeks.Epsilon.copy()\ntimes[greeks.Epsilon != 'Unknown'] = greeks.Epsilon[greeks.Epsilon != 'Unknown'].map(lambda x: datetime.strptime(x,'%m/%d/%Y').toordinal())\ntimes[greeks.Epsilon == 'Unknown'] = np.nan","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:04.750986Z","iopub.execute_input":"2023-08-10T23:52:04.751359Z","iopub.status.idle":"2023-08-10T23:52:04.777353Z","shell.execute_reply.started":"2023-08-10T23:52:04.751326Z","shell.execute_reply":"2023-08-10T23:52:04.776426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred_and_time = pd.concat((train, times), axis=1)\ntest_predictors = test[predictor_columns]\nfirst_category = train.EJ.unique()[1]\ntest_predictors.EJ = test_predictors.EJ.eq(first_category).astype('int')\ntest_pred_and_time = np.concatenate((test_predictors, np.zeros((len(test_predictors), 1)) + train_pred_and_time.Epsilon.max() + 1), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:04.778628Z","iopub.execute_input":"2023-08-10T23:52:04.77904Z","iopub.status.idle":"2023-08-10T23:52:04.794748Z","shell.execute_reply.started":"2023-08-10T23:52:04.779006Z","shell.execute_reply":"2023-08-10T23:52:04.793583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ros = RandomOverSampler(random_state=42)\n\ntrain_ros, y_ros = ros.fit_resample(train_pred_and_time, greeks.Alpha)\nprint('Original dataset shape')\nprint(greeks.Alpha.value_counts())\nprint('Resample dataset shape')\nprint( y_ros.value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:04.796334Z","iopub.execute_input":"2023-08-10T23:52:04.79682Z","iopub.status.idle":"2023-08-10T23:52:04.841094Z","shell.execute_reply.started":"2023-08-10T23:52:04.796784Z","shell.execute_reply":"2023-08-10T23:52:04.840106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_ros = train_ros.drop(['Class', 'Id'],axis=1)\ny_ = train_ros.Class\nyt = Ensemble()\nm = training(yt,x_ros,y_,y_ros)\ny_.value_counts()/y_.shape[0]\ny_pred = m.predict_proba(test_pred_and_time)\nprobabilities = np.concatenate((y_pred[:,:1], np.sum(y_pred[:,1:], 1, keepdims=True)), axis=1)\np0 = probabilities[:,:1]\n# p0[p0 > 0.95] = 1\n# p0[p0 < 0.05] = 0\nsubmission = pd.DataFrame(test[\"Id\"], columns=[\"Id\"])\nsubmission[\"class_0\"] = p0\nsubmission[\"class_1\"] = 1 - p0\nsubmission.to_csv('submission.csv', index=False)\nsubmission_df = pd.read_csv('submission.csv')\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:52:04.842453Z","iopub.execute_input":"2023-08-10T23:52:04.842789Z"},"trusted":true},"execution_count":null,"outputs":[]}]}