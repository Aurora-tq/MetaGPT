{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hi to all! \nI have added two models with slightly modified hyperparameters to this excellent notebook:https://www.kaggle.com/code/vaibhavjain2004/public-krni-pdi.\nThe best result is version 3, version 4 only added description.\nGood luck to everyone!","metadata":{"execution":{"iopub.status.busy":"2023-06-25T10:08:23.66068Z","iopub.execute_input":"2023-06-25T10:08:23.661832Z","iopub.status.idle":"2023-06-25T10:08:44.412009Z","shell.execute_reply.started":"2023-06-25T10:08:23.661787Z","shell.execute_reply":"2023-06-25T10:08:44.409631Z"}}},{"cell_type":"code","source":"!pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr/pip-packages\n!mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n!cp /kaggle/input/pip-packages-icr/pip-packages/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:10.896685Z","iopub.execute_input":"2023-07-02T19:04:10.897147Z","iopub.status.idle":"2023-07-02T19:04:30.513432Z","shell.execute_reply.started":"2023-07-02T19:04:10.897114Z","shell.execute_reply":"2023-07-02T19:04:30.511491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder,normalize\nfrom sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.impute import SimpleImputer\nimport imblearn\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nimport xgboost\nimport inspect\nfrom collections import defaultdict\nfrom tabpfn import TabPFNClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-02T19:04:30.516818Z","iopub.execute_input":"2023-07-02T19:04:30.517402Z","iopub.status.idle":"2023-07-02T19:04:35.870972Z","shell.execute_reply.started":"2023-07-02T19:04:30.517342Z","shell.execute_reply":"2023-07-02T19:04:35.869523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ntest = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\nsample = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')\ngreeks = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/greeks.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:35.872578Z","iopub.execute_input":"2023-07-02T19:04:35.873282Z","iopub.status.idle":"2023-07-02T19:04:35.937694Z","shell.execute_reply.started":"2023-07-02T19:04:35.873249Z","shell.execute_reply":"2023-07-02T19:04:35.936515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lb = LabelEncoder()\n# train['EJ'] = lb.fit_transform(train['EJ']).astype(float)\n# test['EJ'] = lb.fit_transform(test['EJ']).astype(float)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:35.940963Z","iopub.execute_input":"2023-07-02T19:04:35.941552Z","iopub.status.idle":"2023-07-02T19:04:35.948261Z","shell.execute_reply.started":"2023-07-02T19:04:35.941511Z","shell.execute_reply":"2023-07-02T19:04:35.946508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_category = train.EJ.unique()[0]\ntrain.EJ = train.EJ.eq(first_category).astype('int')\ntest.EJ = test.EJ.eq(first_category).astype('int')","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:35.950136Z","iopub.execute_input":"2023-07-02T19:04:35.95086Z","iopub.status.idle":"2023-07-02T19:04:35.973542Z","shell.execute_reply.started":"2023-07-02T19:04:35.950816Z","shell.execute_reply":"2023-07-02T19:04:35.972122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_under_sampler(df):\n    # Calculate the number of samples for each label. \n    neg, pos = np.bincount(df['Class'])\n\n    # Choose the samples with class label `1`.\n    one_df = df.loc[df['Class'] == 1] \n    # Choose the samples with class label `0`.\n    zero_df = df.loc[df['Class'] == 0]\n    # Select `pos` number of negative samples.\n    # This makes sure that we have equal number of samples for each label.\n    zero_df = zero_df.sample(n=pos)\n\n    # Join both label dataframes.\n    undersampled_df = pd.concat([zero_df, one_df])\n\n    # Shuffle the data and return\n    return undersampled_df.sample(frac = 1)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:35.975152Z","iopub.execute_input":"2023-07-02T19:04:35.975533Z","iopub.status.idle":"2023-07-02T19:04:35.98833Z","shell.execute_reply.started":"2023-07-02T19:04:35.975468Z","shell.execute_reply":"2023-07-02T19:04:35.986708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_good = random_under_sampler(train)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:35.990113Z","iopub.execute_input":"2023-07-02T19:04:35.991048Z","iopub.status.idle":"2023-07-02T19:04:36.024988Z","shell.execute_reply.started":"2023-07-02T19:04:35.991006Z","shell.execute_reply":"2023-07-02T19:04:36.023449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_good.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.026725Z","iopub.execute_input":"2023-07-02T19:04:36.027298Z","iopub.status.idle":"2023-07-02T19:04:36.036725Z","shell.execute_reply.started":"2023-07-02T19:04:36.027262Z","shell.execute_reply":"2023-07-02T19:04:36.03543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor_columns = [n for n in train.columns if n != 'Class' and n != 'Id']\nx= train[predictor_columns]\ny = train['Class']","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.038383Z","iopub.execute_input":"2023-07-02T19:04:36.039096Z","iopub.status.idle":"2023-07-02T19:04:36.053292Z","shell.execute_reply.started":"2023-07-02T19:04:36.03896Z","shell.execute_reply":"2023-07-02T19:04:36.052218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_norm = np.array(x_norm)\n# y_ros = np.array(y_ros)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.05797Z","iopub.execute_input":"2023-07-02T19:04:36.058824Z","iopub.status.idle":"2023-07-02T19:04:36.063508Z","shell.execute_reply.started":"2023-07-02T19:04:36.058788Z","shell.execute_reply":"2023-07-02T19:04:36.062528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold as KF, GridSearchCV\ncv_outer = KF(n_splits = 10, shuffle=True, random_state=42)\ncv_inner = KF(n_splits = 5, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.06492Z","iopub.execute_input":"2023-07-02T19:04:36.065373Z","iopub.status.idle":"2023-07-02T19:04:36.077281Z","shell.execute_reply.started":"2023-07-02T19:04:36.065325Z","shell.execute_reply":"2023-07-02T19:04:36.075966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def balanced_log_loss(y_true, y_pred):\n    # y_true: correct labels 0, 1\n    # y_pred: predicted probabilities of class=1\n    # calculate the number of observations for each class\n    N_0 = np.sum(1 - y_true)\n    N_1 = np.sum(y_true)\n    # calculate the weights for each class to balance classes\n    w_0 = 1 / N_0\n    w_1 = 1 / N_1\n    # calculate the predicted probabilities for each class\n    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n    p_0 = 1 - p_1\n    # calculate the summed log loss for each class\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n    log_loss_1 = -np.sum(y_true * np.log(p_1))\n    # calculate the weighted summed logarithmic loss\n    # (factgor of 2 included to give same result as LL with balanced input)\n    balanced_log_loss = 2*(w_0 * log_loss_0 + w_1 * log_loss_1) / (w_0 + w_1)\n    # return the average log loss\n    return balanced_log_loss/(N_0+N_1)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.078864Z","iopub.execute_input":"2023-07-02T19:04:36.079248Z","iopub.status.idle":"2023-07-02T19:04:36.091838Z","shell.execute_reply.started":"2023-07-02T19:04:36.079218Z","shell.execute_reply":"2023-07-02T19:04:36.090579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Ensemble():\n    def __init__(self):\n        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n\n        self.classifiers =[xgboost.XGBClassifier(n_estimators=100,max_depth=3,learning_rate=0.2,subsample=0.9,colsample_bytree=0.85),\n                          \n                           xgboost.XGBClassifier(),\n                           TabPFNClassifier(N_ensemble_configurations=24),\n                          \n                          TabPFNClassifier(N_ensemble_configurations=64)]\n    \n    def fit(self,X,y):\n        y = y.values\n        unique_classes, y = np.unique(y, return_inverse=True)\n        self.classes_ = unique_classes\n        first_category = X.EJ.unique()[0]\n        X.EJ = X.EJ.eq(first_category).astype('int')\n        X = self.imputer.fit_transform(X)\n#         X = normalize(X,axis=0)\n        for classifier in self.classifiers:\n            if classifier==self.classifiers[2] or classifier==self.classifiers[3]:\n                classifier.fit(X,y,overwrite_warning =True)\n            else :\n                classifier.fit(X, y)\n     \n    def predict_proba(self, x):\n        x = self.imputer.transform(x)\n#         x = normalize(x,axis=0)\n        probabilities = np.stack([classifier.predict_proba(x) for classifier in self.classifiers])\n        averaged_probabilities = np.mean(probabilities, axis=0)\n        class_0_est_instances = averaged_probabilities[:, 0].sum()\n        others_est_instances = averaged_probabilities[:, 1:].sum()\n        # Weighted probabilities based on class imbalance\n        new_probabilities = averaged_probabilities * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(averaged_probabilities.shape[1])]])\n        return new_probabilities / np.sum(new_probabilities, axis=1, keepdims=1) ","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.093457Z","iopub.execute_input":"2023-07-02T19:04:36.094534Z","iopub.status.idle":"2023-07-02T19:04:36.108996Z","shell.execute_reply.started":"2023-07-02T19:04:36.094494Z","shell.execute_reply":"2023-07-02T19:04:36.10794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.110444Z","iopub.execute_input":"2023-07-02T19:04:36.112149Z","iopub.status.idle":"2023-07-02T19:04:36.238432Z","shell.execute_reply.started":"2023-07-02T19:04:36.112088Z","shell.execute_reply":"2023-07-02T19:04:36.237324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training(model, x,y,y_meta):\n    outer_results = list()\n    best_loss = np.inf\n    split = 0\n    splits = 5\n    models=[]\n    for train_idx,val_idx in tqdm(cv_inner.split(x), total = splits):\n        split+=1\n        x_train, x_val = x,x.iloc[val_idx]#x.iloc[train_idx],x.iloc[val_idx]\n        y_train, y_val = y_meta, y.iloc[val_idx]#y_meta.iloc[train_idx], y.iloc[val_idx]\n        #model = Ensemble()        \n        model.fit(x_train, y_train)\n        models.append(model)\n        y_pred = model.predict_proba(x_val)\n        probabilities = np.concatenate((y_pred[:,:1], np.sum(y_pred[:,1:], 1, keepdims=True)), axis=1)\n        p0 = probabilities[:,:1]\n        p0[p0 > 0.86] = 1\n        p0[p0 < 0.14] = 0\n        y_p = np.empty((y_pred.shape[0],))\n        for i in range(y_pred.shape[0]):\n            if p0[i]>=0.5:\n                y_p[i]= False\n            else :\n                y_p[i]=True\n        y_p = y_p.astype(int)\n        loss = balanced_log_loss(y_val,y_p)\n\n        if loss<best_loss:\n            best_model = model\n            best_loss = loss\n            print('best_model_saved')\n        outer_results.append(loss)\n        print('>val_loss=%.5f, split = %.1f' % (loss,split))\n    print('LOSS: %.5f' % (np.mean(outer_results)))\n    return best_model, models\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.240103Z","iopub.execute_input":"2023-07-02T19:04:36.24065Z","iopub.status.idle":"2023-07-02T19:04:36.254105Z","shell.execute_reply.started":"2023-07-02T19:04:36.240611Z","shell.execute_reply":"2023-07-02T19:04:36.252919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\ntimes = greeks.Epsilon.copy()\ntimes[greeks.Epsilon != 'Unknown'] = greeks.Epsilon[greeks.Epsilon != 'Unknown'].map(lambda x: datetime.strptime(x,'%m/%d/%Y').toordinal())\ntimes[greeks.Epsilon == 'Unknown'] = np.nan","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.255729Z","iopub.execute_input":"2023-07-02T19:04:36.256119Z","iopub.status.idle":"2023-07-02T19:04:36.291956Z","shell.execute_reply.started":"2023-07-02T19:04:36.256088Z","shell.execute_reply":"2023-07-02T19:04:36.290969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred_and_time = pd.concat((train, times), axis=1)\ntest_predictors = test[predictor_columns]\nfirst_category = test_predictors.EJ.unique()[0]\ntest_predictors.EJ = test_predictors.EJ.eq(first_category).astype('int')\ntest_pred_and_time = np.concatenate((test_predictors, np.zeros((len(test_predictors), 1)) + train_pred_and_time.Epsilon.max() + 1), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.293368Z","iopub.execute_input":"2023-07-02T19:04:36.294444Z","iopub.status.idle":"2023-07-02T19:04:36.311507Z","shell.execute_reply.started":"2023-07-02T19:04:36.294409Z","shell.execute_reply":"2023-07-02T19:04:36.310172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ros = RandomOverSampler(random_state=42)\n\ntrain_ros, y_ros = ros.fit_resample(train_pred_and_time, greeks.Alpha)\nprint('Original dataset shape')\nprint(greeks.Alpha.value_counts())\nprint('Resample dataset shape')\nprint( y_ros.value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.312999Z","iopub.execute_input":"2023-07-02T19:04:36.313354Z","iopub.status.idle":"2023-07-02T19:04:36.363529Z","shell.execute_reply.started":"2023-07-02T19:04:36.313324Z","shell.execute_reply":"2023-07-02T19:04:36.362166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_ros = train_ros.drop(['Class', 'Id'],axis=1)\ny_ = train_ros.Class","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.364617Z","iopub.execute_input":"2023-07-02T19:04:36.364955Z","iopub.status.idle":"2023-07-02T19:04:36.375382Z","shell.execute_reply.started":"2023-07-02T19:04:36.364928Z","shell.execute_reply":"2023-07-02T19:04:36.373789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yt = Ensemble()","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:36.377216Z","iopub.execute_input":"2023-07-02T19:04:36.377603Z","iopub.status.idle":"2023-07-02T19:04:37.507793Z","shell.execute_reply.started":"2023-07-02T19:04:36.377572Z","shell.execute_reply":"2023-07-02T19:04:37.506529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m,models = training(yt,x_ros,y_,y_ros)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T19:04:37.51071Z","iopub.execute_input":"2023-07-02T19:04:37.511629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_.value_counts()/y_.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = m.predict_proba(test_pred_and_time)\n#y_pred_list = []\n#for m in models:\n#    y_pred_list.append(m.predict_proba(test_pred_and_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred=np.mean(y_pred_list, axis=0)\nprobabilities = np.concatenate((y_pred[:,:1], np.sum(y_pred[:,1:], 1, keepdims=True)), axis=1)\np0 = probabilities[:,:1]\np0[p0 > 0.60] = 1\np0[p0 < 0.26] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(test[\"Id\"], columns=[\"Id\"])\nsubmission[\"class_0\"] = p0\nsubmission[\"class_1\"] = 1 - p0\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv('submission.csv')\nsubmission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}